{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Convolutional Neural Networks for classification (CNNs/ConvNets) of MNIST dataset\n",
    "The MNIST dataset is an acronym that stands for the Modified National Institute of Standards and Technology dataset.\n",
    "\n",
    "It is a dataset of 60,000 small square 28Ã—28 pixel grayscale images of handwritten single digits between 0 and 9.\n",
    "\n",
    "\n",
    "\n",
    "The task is to classify a given image of a handwritten digit into one of 10 classes representing integer values from 0 to 9, inclusively.\n",
    "\n",
    "In fact, even Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API. Therefore, we will start with the following two lines to import TensorFlow and MNIST dataset under the Keras API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the tensorflow and downoading dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings \n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import tensorflow \n",
    "import tensorflow as tf\n",
    "\n",
    "# Data Split\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f73db04c0d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import plt\n",
    "import matplotlib.pyplot as plt\n",
    "# print a radom image \n",
    "image_index = 180 # You may select anything up to 60,000 80. 70\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the dataset ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping and Normalizing the Images\n",
    "To be able to use the dataset in Keras API, we need 4-dims NumPy arrays. However, as we see above, our array is 3-dims. In addition, we must normalize our data as it is always required in neural network models. We can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code). This can be done with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# Making sure that the values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32') # convert the data with #astype\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Convolutional Neural Network\n",
    "We will build our model by using high-level Keras API which uses either TensorFlow or Theano on the backend. There are several high-level TensorFlow APIs such as Layers, Keras, and Estimators which helps us create neural networks with high-level knowledge. However, this may lead to confusion since they all vary in their implementation structure. Therefore, if you see completely different codes for the same neural network although they all use TensorFlow, this is why. We will use the most straightforward API which is Keras. Therefore, I will import the Sequential Model from Keras and add Conv2D, MaxPooling, Flatten, Dropout, and Dense layers. I have already talked about Conv2D, Maxpooling, and Dense layers. In addition, Dropout layers fight with the overfitting by disregarding some of the neurons while training while Flatten layers flatten 2D arrays to 1D arrays before building the fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-28 15:22:43.948866: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-09-28 15:22:43.948908: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-09-28 15:22:43.948935: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jupyter-3295): /proc/driver/nvidia/version does not exist\n",
      "2022-09-28 15:22:43.949291: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2)) # Dropout is aimed to prevent the network form overfittings\n",
    "model.add(Dense(10,activation=tf.nn.softmax)) # the number of final Dense layer is the number of output classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may experiment with any number for the first Dense layer; however, the final Dense layer must have 10 neurons since we have 10 number classes (0, 1, 2, â€¦, 9). You may always experiment with kernel size, pool size, activation functions, dropout rate, and a number of neurons in the first Dense layer to get a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling and Fitting the Model\n",
    "With the above code, we created a non-optimized empty CNN. Now it is time to set an optimizer with a given loss function that uses a metric. Then, we can fit the model by using our train data. We will use the following code for these tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2093 - accuracy: 0.9374\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0837 - accuracy: 0.9746\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0583 - accuracy: 0.9819\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0474 - accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0350 - accuracy: 0.9887\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0295 - accuracy: 0.9903\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0240 - accuracy: 0.9920\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0226 - accuracy: 0.9923\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0191 - accuracy: 0.9935\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0192 - accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f73db4fe8b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model \n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment with the optimizer, loss function, metrics, and epochs. However, I can say that adam optimizer is usually out-performs the other optimizers. I am not sure if you can actually change the loss function for multi-class classification. Feel free to experiment and comment below. The epoch number might seem a bit small. However, you will reach to 98â€“99% test accuracy. Since the MNIST dataset does not require heavy computing power, you may easily experiment with the epoch number as well.\n",
    "Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "Finally, you may evaluate the trained model with x_test and y_test using one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0582 - accuracy: 0.9858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05820629373192787, 0.98580002784729]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model \n",
    "model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved 98.41% accuracy with such a basic model. To be frank, in many image classification cases (e.g. for autonomous cars), we cannot even tolerate 0.1% error since, as an analogy, it will cause 1 accident in 1000 cases. However, for our first model, I would say the result is still pretty good. We can also make individual predictions with the following cod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 106ms/step\n",
      "The prediction for the following image is:  9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# try model on a random image \n",
    "image_index = 105\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(\"The prediction for the following image is: \",pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model will classify the image as a â€˜9â€™ and here is the visual of the image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further inofrmation above the topic please refer to a good reference :\n",
    "#### Reference: \n",
    "https://cs231n.github.io/convolutional-networks/#conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Damage sites in the microstructure of dual phase steel :\n",
    "the damage sites are classified w.r.t the appearance in the microstructure and they are basically devided to 4 classes . out of which martensite cracks, interface decohisions, notchs are defomration induced damages and inclusions are not defoemration induced damages. \n",
    "\n",
    "<figure>\n",
    "<img src=\"example.png\" width='1000'>\n",
    "<figcaption></figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "#### Damage sites in the microstructure of dual phase steel : \n",
    "\n",
    "What kind of multi-classe data do you have your field of research? Are you interested in thei classification and statistic extraction ? Refer to our papaers if you are like to know how we did it.;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference: \n",
    "i) S. Medghalchi et al. Damage Analysis in Dual-Phase Steel Using Deep Learning: Transfer from Uniaxial to Biaxial Straining Conditions by Image Data Augmentation, JOM, 2020\n",
    "\n",
    "\n",
    "ii) C. Kusche et al. Large-area, high-resolution characterisation and classification of damage mechanisms in dual-phase steel using deep learning. PloS one, 2019.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
